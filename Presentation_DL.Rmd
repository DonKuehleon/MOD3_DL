---
title: "Deep Learning in practice"
subtitle: ""
author: "Stefan Kunz"
# date: "2016/12/12"
institute: "AG Landscape Ecology"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: solarized-light
      highlightLines: true
      countIncrementalSlides: false
      # countdown: 60000
    seal: false
---

class: title-slide

.bg-text[

# Deep Learning in practice
### 
<hr />

January, 14th

Ralf B. Sch√§fer & Stefan Kunz

University of Koblenz-Landau

]

--

.center[
<img src="Pictures/rbs_express.jpg" style="width: 20%"/>
]

<style type="text/css">
.remark-slide-content {
    font-size: 20px;
    padding: 1em 4em 1em 4em;
}
.small {
  font-size: 15px;
}
</style>


```{r xaringan-themer, include=FALSE, warning=FALSE}
library(knitr)
library(xaringanthemer)
library(xaringanExtra)
# library(showtext)
# style_duo(primary_color = "#43418A", 
#           secondary_color = "#F97B64")
style_solarized_light(header_color = "steelblue")
```

```{r xaringan-extra-styles, include = FALSE}
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```

---

### Libraries & frameworks for deep learning models

#### R packages that implement NN:

- *neuralnet*, *nnet*, *MXNet*, *tensorflow & keras*, *torch*, *...*

#### Frameworks for training deep learning models:

- Developed by industry (Google, Facebook, ...) and research institutions

- Previously written code blocks have been re-used for new tools & algorithms 

- Created with *Python*, *C++*, *Lua*, ...

- Mostly used with Python 

---

### Frameworks for training deep learning models:

- <img src="Pictures/TensorFlowLogo.svg" style="width: 12%"/>
  - Library for training and inference of deep neural networks developed for internal use by Google (2011)
  - R: https://tensorflow.rstudio.com/

--

- <img src="Pictures/Pytorch.png" style="width: 16%"/>
  - Developd by Facebook in 2016 (open-source) for *Python*  
  - R: torch package https://torch.mlverse.org/packages/

--

- <img src="Pictures/Keras.png" style="width: 12%"/>
  - Open-source high-level deep learning framework by Francois Chollet (written in *Python*)
  - Easy to use, supports tensorflow and other deep learning libraries as backend 
  - Keras now part of TensorFlow


???
_Keras: coding the model and the training, TensorFlow for high-performance data pipeline,_ 
_provides also backend to other frameworks (e.g. Theano)_
_Keras: in f10-15 lines of code a deep learning model can be defined and trained_

_Tensorflow source: https://upload.wikimedia.org/wikipedia/commons/1/11/TensorFlowLogo.svg_

_Mention that there are also frameworks for inference, e.g. to make predictions inside an app_

---

### Frameworks for training deep learning models

- <img src="Pictures/TensorFlowLogo.svg" style="width: 12%"/>

- <img src="Pictures/Keras.png" style="width: 12%"/>

- <img src="Pictures/Pytorch.png" style="width: 16%"/>


- Sharing models: Open Neural Network Exchange (ONNX)

???
ONNX: Standard format for machine learning models; provides conversion of models between frameworks
Computation graph models, definitions for operators and standard data types
Could use R with ONNX
There is also the https://github.com/rstudio/tensorflow and 
https://cran.r-project.org/web/packages/keras/vignettes/index.html
https://torch.mlverse.org/

---

### Small example of a single hidden layer Neural Network (NN)

- Will use the **nnet** package

- Acess through **caret** package


--

- Provides an uniform interface for a large variety of different modeling functions in R

```{r, eval = FALSE}
library(nnet)
library(caret)
caret::train(
  form,
  method = "nnet",
  tuneGrid,
  ...
)
```

--

- Overview of supported models: http://topepo.github.io/caret/train-models-by-tag.html


???
_Package by Max Kuhn_
_set of functions to streamlining predictive modelling_
_Tools for data splitting, pre-processing, feature selection, resampling, variable importance_
_uniform syntax_

---

### Small example of a single hidden layer NN

#### Nanopart data

* Data: nanoparticles measured with and without fulvic acid 

```{r, message=FALSE}
# load Set_up script
source(file.path(getwd(), "R", "Set_up.R"))

# load data
nanopart <- readRDS(file.path(data_in, "nanopart_preproc.RDS"))
dim(nanopart)
```

---

### Small example of a single hidden layer NN

#### Nanopart data

- Variables: molecular masses with signal intensities 

```{r}
names(nanopart)[1:4]
summary(nanopart$Mass_12_00)
summary(nanopart$fulvic_acid)
```


---

### Small example of a single hidden layer NN

#### Data preparation nanopart

- Normalising the data either to $[0, 1]$ or scaling to $\mu = 0$ and $\sigma = 1$ to avoid the dominance of variables with large values

--

```{r}
# scaling (mean zero, sd 1)
stand_nanopart <-
  scale(nanopart[, -ncol(nanopart)], 
        center = TRUE,
        scale = TRUE) %>%
  as.data.frame() %>%
  cbind(., "fulvic_acid" = nanopart[, "fulvic_acid"])

# check mean and sd
summary(stand_nanopart$Mass_12_00)
sd(stand_nanopart$Mass_12_00)
```

???
_remember every input gets multiplied by the weights and then summed up at the neuron_
_the resulting value is then applied to the activation function_ 
_If data are not in the same range, large valued variables will dominate_
_If training long enough than weights would adjust for large valued variables, however this is not desirable_

_uniform and highly non linear variables - normalize_
_otherwise standardize_


---

### Small example of a single hidden layer NN
#### Data preparation nanopart

- Divide data into test and training data

- *caret::createDataParatition()* does sample from within factors

```{r}
# index <- sample(1:nrow(stand_nanopart), 
# ceiling(0.75 * nrow(stand_nanopart)))
# train <- stand_nanopart[index, ]
# test <- stand_nanopart[-index, ]

ind <- createDataPartition(stand_nanopart$fulvic_acid, p = 0.75)
train <- stand_nanopart[ind[[1]], ]
test <- stand_nanopart[-ind[[1]], ]
```


---

### Small example of a single hidden layer NN 
#### Training

```{r} 
str(train$fulvic_acid)

nn_nanopart <- train(
  fulvic_acid ~ .,
  data = train,
  method = "nnet", 
  tuneGrid = expand.grid(size = 5, # number of hidden layers
                         decay = 5e-4), # regularization parameter
  maxit = 100, 
  metric = "Accuracy"
)
```

???
_mention tuning and preprocessing_
_linout argument: output layer linear or sigmoid_

---

### Small example of a single hidden layer NN 

```{r}
NeuralNetTools::plotnet(nn_nanopart)
```


???
_Nr of weights = parameters?_

---
### Small example of a single hidden layer NN 
#### Predictions

```{r}
# training data
result_train <- predict(nn_nanopart, newdata = train)
conf_train <- caret::confusionMatrix(result_train, 
                                     train$fulvic_acid)

conf_train
```

---

### Small example of a single hidden layer NN 
#### Predictions

```{r}
# test data:
results_test <- predict(nn_nanopart, newdata=test)
conf_test <- confusionMatrix(results_test, 
                             test$fulvic_acid)

conf_test
```

___

### Small example of a single hidden layer NN 
#### Predictions

```{r, eval = FALSE}
# get the probabilities for each class in the test set
predict(nn_nanopart,
        newdata = test,
        type = 'prob')
```


---
### Small example of a single hidden layer NN 
#### Predictions

- Prediction accuracy on test and traing dataset is 1

- Model has potentially overfitted the data

- Number of weights?


```{r}
# input layer nodes * hidden layer nodes + 
# hidden layer nodes * output layer nodes +
# bias (1) * hidden layers + bias (1) * output layer
119*5 + 5*1 + 1*5 + 1*1

# confirm with
nn_nanopart$finalModel
```

---

### Small example of a single hidden layer NN 

Overfitting: 

- Typically: 
  - Very good performance on training data, bad performance on test data
  (i.e. model has learned the noise in the training data)

  - Many parameters and small datasets 

--

- Circumvent: Regularization & DropOut

--

- In practice: NN in deep learning have often more parameters than training samples

???
_DropOut similarly to LASSO_
_Maybe even the network structure prevents overfitting - ongoing research (Zhang et al. 2017)_
_Many parameters also means high flexibility_

---

### Small example of a single hidden layer NN 
#### Relative variable importance

- Deconstructing model weights: identification of all weighted connections between an input node and the output node(s)

```{r}
VI <- garson(nn_nanopart)
VI$data[VI$data$x_names == "Mass_39_03", ]
```


---

### Small example of a single hidden layer NN 
#### Task: 

Previous analysis of the data suggested that the following masses seem to
be important to distinguish samples that contained fulvic acid from samples
without fulvic acid:
**Mass_39_03**, 
**Mass_38_02**, 
**Mass_65_04**, 
**Mass_53_04**, 
**Mass_45_98**

1. Create a neural network classifier with only these 5 parameters, predicting whether
a sample contained fulvic acid or not. *Bonus: vary the number of hidden units between 2 and 5.*

2. How many weights has the neural network? 

3. Compare the results with a logistic regression model



---
### Deep learning (DL) algorithms are data hungry

--

- DL algorithms can only detect what they have previously seen

- The bigger the dataset, the better the classification accuracy (Marcus, 2018)

- Each classification category should be sufficiently represented in the training data  


---
### Deep learning (DL) algorithms are data hungry

- One possible solution:  **Transfer learning**

--

- Extract knowledge from *source task* (e.g. a pretrained model) and apply to *target task*

--
<img src="Pictures/TL_explan.png" style="width: 100%"/>


???
_That means using an existing model, trained on a large dataset and tuning it to our dataset_



---
### Transfer learning

#### Advantages

- Reduced training time

- Smaller datasets (hundreds to thousands of samples)
--


#### Prerequisites: 

- Availability of pretrained models  

```{r, include=FALSE}
mod_architectures <- data.frame(
  Task = c(
    "Image Classification",
    "Text classification",
    "Image segmentation",
    "Image translation",
    "Object detection",
    "Speech generation"
  ),
  `Examples` = c(
    "ResNet-152 (2015), MobileNet (2017)",
    "BERT (2018), XLNet (2019)",
    "U-Net (2015), DeepLabV3 (2018)",
    "Pix2Pix (2017)",
    "YOLO9000 (2016), Mask R-CNN (2017)",
    "WaveNet (2016)"
  )
)
```

```{r, echo = FALSE}
knitr::kable(x = mod_architectures, format = "html")
```

???
_Say here: 

Model architecture: Layers, graph of nodes and edges
1) input 2) getting output 3) comparison with labels/predictions vs expectations
4) propagating magnitude of error back to the model so that it can learn

Result of training: Weights of the nodes

Types of nodes: different themes of model architectures -> CNNs, RNNs, GANs

We will use MobileNet(), briefly introduce: Developed and trained by google for mobile devices (limited computational power and space). Could google and find model as well as accuracy metrics 

_TODO: What is image segmentation and image translation?_




---
### Transfer Learning

#### Prerequisites: 

- Availability of pretrained models  

--

- Large annotated datasets (e.g. ImageNet)

<img src="Pictures/imagenet.png" style="width: 75%"/>


.footnote[.small[*http://image-net.org/explore*]]


---



### Transfer Learning

#### Prerequisites: 

- Availability of pretrained models 

- Large annotated datasets (e.g. ImageNet)

- Developments in computational power, i.e., faster and cheaper GPUs

- Availability of algorithms (model architecture, optimizers,...)

---



### Transfer Learning using CNNs for image classification


- Remove last few layers and "freeze" generic layers 

<img src="Pictures/cnn_transfer_learning.png" style="width: 75%"/>



.footnote[.small[*Koul, Ganju & Kasam (2020)*]]


???
_First layers more general, middle-layers already specific, last layers very specific_
_freeze: weights stay the same_
_say that features relate to characteristics in the pictures not to the variables_

---

### Finetuning 

- Unfreeze few of the frozen layers

- Dependent on the amount of task-specific data

<img src="Pictures/finetuning.png" style="width: 75%"/>


.footnote[.small[*Koul, Ganju & Kasam (2020)*]]

???
_allowing more weights to change_

---



### Examples in ecology 


- Transfer learning & CNNs to identify species of *Chironomidae* (Milo≈°eviƒá et al. 2019)

<img src="Pictures/chironomidae_classifier.png" style="width: 65%"/>


???
_What is shown here?_

---

### Examples in ecology 

#### Using transfer learning:

- CNNs to identify species of *Chironomidae* (Milo≈°eviƒá et al. 2019)

--

- Object detection (R-CNN/YOLO) to label camera trap images (Schneider et al. 2018)

--

#### Overview on recent studies:


- Review: Christin et al. (2019) - Applications of deep learning in ecology


???
_Most Papers very recently published in this field (> 2017)_
_Usage not only for image classification -> think outside of the box (Max Joseph)_

---

### Image classification example in *Python* using transfer learning


- We are using an existing pretrained CNN (*MobileNet()*)

- Its weights are trained on a large annotated image database (ImageNet)

- We will "freeze" most of the generic layers

- We will exchange few of the last layers (specific) to customize the model
for our classification task

--

- We will classify:

<img src="Pictures/cat_vs_dog.jpeg" style="width: 35%"/>

---

### Applications

.center[

Art: https://deepart.io/

<img src="Pictures/rbs_express.jpg" style="width: 20%"/>

]

--

.center[

<img src="Pictures/rbs.png" style="width: 20%"/>
]



---
### References

#### Papers:

- Christin, S., Hervet, √â., & Lecomte, N. (2019). Applications for deep learning in ecology. Methods in Ecology and Evolution, 10(10), 1632‚Äì1644. https://doi.org/10.1111/2041-210X.13256


- Marcus, G. (2018). Deep Learning: A Critical Appraisal.
ArXiv:1801.00631. http://arxiv.org/abs/1801.00631

- Milo≈°eviƒá, D., Milosavljeviƒá, A., Prediƒá, B., Medeiros, A. S., Saviƒá-Zdravkoviƒá, D., Stojkoviƒá Piperac, M., Kostiƒá, T., Spasiƒá, F., & Leese, F. (2020). Application of deep learning in aquatic bioassessment: Towards automated identification of non-biting midges. Science of The Total Environment, 711, 135160. https://doi.org/10.1016/j.scitotenv.2019.135160

- Schneider, S., Taylor, G. W., & Kremer, S. C. (2018). Deep Learning Object Detection Methods for Ecological Camera Trap Data. arXiv:1803.10842 [cs]. http://arxiv.org/abs/1803.10842


---

### References

#### Books

Koul A., Ganja S., Kasam M. (2020). Practical Deep Learning for Cloud, Mobile, and Edge. O'Reiley. ISBN: 978-1-392-03486-5


---

### References

#### Images

- Guitar:
https://c1.zzounds.com/media/productmedia/fit,2018by3200/quality,85/1_Full_Straight_Front_NA-b2c2db10f401d973c12a0e86294f5f7c.jpg
 

- Ukulele:
https://www.picklepwns.com/wp-content/uploads/2019/02/Best-ukulele-chords.jpg

- ImageNet screenshot: 
http://image-net.org/explore

- RBS: 
https://i1.rgstatic.net/ii/profile.image/272184648138758-1441905285191_Q512/Ralf_Bernhard_Schaefer.jpg

- Cats vs dogs: 
https://gsurma.medium.com/image-classifier-cats-vs-dogs-with-convolutional-neural-networks-cnns-and-google-colabs-4e9af21ae7a8

---





